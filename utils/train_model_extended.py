import argparse
import pandas as pd
import lightgbm as lgb
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score


def clean_and_convert(df):
    numeric_cols = [
        "å¹´", "æœˆ", "æ—¥", "ï¼²", "è·é›¢", "æ°´åˆ†", "é ­æ•°", "æ ç•ª", "é¦¬ç•ª",
        "ç”Ÿå¹´", "èª•ç”Ÿæœˆ", "é¦¬é½¢", "å˜å‹ï½µï½¯ï½½ï¾", "äººæ°—", "æ–¤é‡", "ä¸ŠãŒã‚Š3F", "3ï½ºï½°ï¾…ï½°", "4ï½ºï½°ï¾…ï½°"
    ]
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
    return df


def extract_features(df):
    numeric_cols = [
        "å¹´", "æœˆ", "æ—¥", "ï¼²", "è·é›¢", "æ°´åˆ†", "é ­æ•°", "æ ç•ª", "é¦¬ç•ª",
        "ç”Ÿå¹´", "èª•ç”Ÿæœˆ", "é¦¬é½¢", "å˜å‹ï½µï½¯ï½½ï¾", "äººæ°—", "æ–¤é‡", "ä¸ŠãŒã‚Š3F", "3ï½ºï½°ï¾…ï½°", "4ï½ºï½°ï¾…ï½°"
    ]
    categorical_cols = ["è„šè³ª", "é¨æ‰‹", "å ´å", "æ€§åˆ¥", "å¤©å€™"]

    df = clean_and_convert(df)
    df_clean = df.copy()

    if df_clean.empty:
        return pd.DataFrame()

    existing_cat_cols = [col for col in categorical_cols if col in df_clean.columns]
    df_encoded = pd.get_dummies(df_clean[existing_cat_cols]) if existing_cat_cols else pd.DataFrame(index=df_clean.index)

    features = pd.concat([df_clean[numeric_cols], df_encoded], axis=1)
    return features


def main(input_csv, output_model, target_column):
    df = pd.read_csv(input_csv, encoding="utf-8", low_memory=False)

    if target_column not in df.columns:
        if target_column == "win":
            print("ğŸ“‹ winåˆ—ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆç€é †==1ï¼‰")
            df[target_column] = df["ç€é †"].astype(str).str.strip().apply(lambda x: 1 if x == "1" else 0)
        elif target_column == "place":
            print("ğŸ“‹ placeåˆ—ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆç€é †<=3ï¼‰")
            df[target_column] = df["ç€é †"].astype(str).str.strip().apply(lambda x: 1 if x.isnumeric() and int(x) <= 3 else 0)
        else:
            raise ValueError(f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ— '{target_column}' ãŒCSVã«å­˜åœ¨ã—ã¾ã›ã‚“")

    features = extract_features(df)
    labels = df[target_column]

    if features.empty:
        raise ValueError("âŒ å‰å‡¦ç†å¾Œã«è¡ŒãŒ0ä»¶ã§ã™ã€‚å…ƒCSVã«æ•°å€¤ä»¥å¤–ãŒæ··ã–ã£ã¦ã„ã¾ã›ã‚“ã‹ï¼Ÿ")

    print(f"âœ¨ dropna: {len(df)} â†’ {len(features)} è¡Œã«å‰Šæ¸›")

    train_X, val_X, train_y, val_y = train_test_split(features, labels, test_size=0.2, random_state=42)

    lgb_train = lgb.Dataset(train_X, label=train_y)
    lgb_valid = lgb.Dataset(val_X, label=val_y, reference=lgb_train)

    params = {
        'objective': 'binary',
        'metric': 'auc',
        'verbosity': -1,
        'boosting_type': 'gbdt'
    }

    model = lgb.train(
        params,
        lgb_train,
        valid_sets=[lgb_train, lgb_valid],
        num_boost_round=100,
        callbacks=[lgb.early_stopping(stopping_rounds=10)]
    )

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model.save_model(output_model)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {output_model}")

    # ç‰¹å¾´é‡ã®åˆ—åã‚’ä¿å­˜
    with open(output_model + ".columns.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(train_X.columns.tolist()))

    # è©•ä¾¡æŒ‡æ¨™å‡ºåŠ›
    y_pred = model.predict(val_X)
    auc = roc_auc_score(val_y, y_pred)
    acc = accuracy_score(val_y, (y_pred > 0.5).astype(int))
    print(f"ğŸ“Š AUC: {auc:.4f}")
    print(f"ğŸ“Š Accuracy: {acc:.4f}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True)
    parser.add_argument("--model", required=True)
    parser.add_argument("--target", required=True)
    args = parser.parse_args()

    main(args.input, args.model, args.target)
